# 图像分类比赛的各种tricks

最近参加了几个图像分类的比赛，总结了一些图像分类比赛中一些tricks。（框架选择pytorch）

 * 完整代码请移步github：[https://github.com/lxztju/pytorch_classification](https://github.com/lxztju/pytorch_classification) 
 * 如果有帮助请star。

* 数据预处理
* 学习率调整
* 模型选择
* 迁移学习
* 模型融合
* TTA（测试时增强）

参加比赛一般的套路就是，训练一些分类模型，然后从中选择最优模型，最后使用ensample（模型融合）与TTA得到最优结果。

## 数据预处理

数据预处理对于比赛来说，可能是最重要的，数据预处理处理得好，同时选择一个优良的模型，就能在一个比赛中获得较好的成绩。

这一部分的内容，我还没有整理相对较好的程序文件，数据分析的代码，现在只采用一些简单的处理方法。

后期总结出好的数据分析预处理方法，会在github中持续更新代码。

torchvision中transforms中提供了很多的预处理方法：

```python
transforms.Compose([
        transforms.RandomCrop(size),
        transforms.RandomVerticalFlip(),
        transforms.RandomHorizontalFlip(),
        RandomRotate(15, 0.3),
        RandomGaussianBlur(),
        transforms.ToTensor(),
        transforms.Normalize(mean=mean, std=std),
    ])
```

## 学习率调整

学习率调整策略，一般采用带有warmup的学习率调整策略，基本思路就是在训练开始的几个epoch，学习率从小变大，然后在后期的训练过程中逐渐减小学习率。

带有warmup的cosine学习率是我主要使用的，有时候会将替换训练过程中cosine学习率为阶梯式下降的方案。

## 模型选择

一般采用DenseNet， ResNet, ResneXt, EfficientNet这一系列模型进行训练，选择最优的模型。其中我经常使用的模型是ResNeXt与EfficientNet这两个模型组。

这些模型除了EfficientNet之外，其他的模型torchvision上都有提供，EfficientNet在github上也有大佬复现过。

## 迁移学习

由于平常比赛的数据集都相对较小，所以迁移学习是非常必要的，使用在ImageNet上的预训练权重迁移学习是基本的套路。

如果采用的模型较大，数据集又比较小，冻结模型前边的一些层不训练也是防止在数据集较小而模型参数过多导致严重过拟合的问题。

```python
c = 0
for name, p in model.named_parameters():
    c += 1
    if c >=450:
        break
    p.requires_grad = True
```

## 模型融合

一般在训练几个相对较好的模型后，为了提升比赛的结果，可以对多个模型进行融合，将得到的结果进行投票或者加权融合。

## TTA

TTA（测试时增强）是指在测试时将测试图像进行处理（反转，旋转，裁剪）等操作，然后将同一张图片几个处理后的副本进行预测，将结果同样进行投票或者加权融合，这样结果也能够有所提升。

## 利用cnn与svm等结合


在有的分类比赛中，利用cnn提取特征，然后利用svm或者随机森林等进行图像的分类处理的准确率会比直接用全连接层进行分类得到的效果要好一些。在github代码库中包含了这部分实现功能的代码，具体信息，请移步github。